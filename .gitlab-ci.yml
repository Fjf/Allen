###############################################################################
# (c) Copyright 2018-2020 CERN for the benefit of the LHCb Collaboration      #
###############################################################################

variables:
  GIT_SUBMODULE_STRATEGY: recursive
  TARGET_BRANCH: master

  ALLEN_DATA: "/scratch/allen_data"
  LCG_VERSION: "LCG_97apython3"


stages:
  - check         # Ensures the CI environment is valid
  - build         # Builds all projects
  - run           # Runs the tests across architectures
  - test          # Runs various tests of the software
  - publish       # Publishes the results of the tests and runs in channels and grafana


check-env:
  stage: check
  except:
    - /.*/@lhcb/Allen
  script:
    - |
      echo "The Allen CI depends on custom GitLab runners and therefore tests"
      echo "running on forks will fail. Please create a branch in the main"
      echo "repository at https://gitlab.cern.ch/lhcb/Allen/"
    - exit 1


.active_branches: &active_branches
  only:
    refs:
      - master
      - web
      - schedules
      - merge_requests


check-copyright:
  <<: *active_branches

  stage: check
  image: gitlab-registry.cern.ch/ci-tools/ci-worker:cc7
  script:
    - curl -o lb-check-copyright "https://gitlab.cern.ch/lhcb-core/LbDevTools/-/raw/master/LbDevTools/SourceTools.py?inline=False"
    - python lb-check-copyright --license=Apache-2.0 origin/${TARGET_BRANCH}
  needs: []
  allow_failure: true

check-formatting:
  <<: *active_branches
  stage: check
  image: gitlab-registry.cern.ch/lhcb-docker/style-checker
  script:
    - |
      if [ ! -e .clang-format ] ; then
        curl -o .clang-format "https://gitlab.cern.ch/lhcb-parallelization/Allen/raw/master/.clang-format?inline=false"
        echo '.clang-format' >> .gitignore
        git add .gitignore
      fi

    - curl -o lb-format "https://gitlab.cern.ch/lhcb-core/LbDevTools/raw/master/LbDevTools/SourceTools.py?inline=false"

    - python lb-format --format-patch apply-formatting.patch origin/master
  artifacts:
    paths:
      - apply-formatting.patch
    when: on_failure
    expire_in: 1 week
  needs: []
  allow_failure: true

.build_job: &build_job_def
  variables:
    GIT_SUBMODULE_STRATEGY: recursive
  only:
    refs:
      - master
      - web
      - schedules
  stage: build
  script:
    - PREVIOUS_IFS=${IFS}
    - IFS=':' read -ra JOB_NAME_SPLIT <<< "${CI_JOB_NAME}"
    - IFS=${PREVIOUS_IFS}
    - TARGET=${JOB_NAME_SPLIT[0]}
    - SEQUENCE=${JOB_NAME_SPLIT[1]}
    - BUILD_TYPE=${JOB_NAME_SPLIT[2]}
    - ADDITIONAL_OPTIONS="${JOB_NAME_SPLIT[3]}"
    - LCG_ARCHITECTURE=${JOB_NAME_SPLIT[4]}
    - mkdir build_${TARGET}
    - cd build_${TARGET}
    - yum install -y numactl-libs
    - source /cvmfs/sft.cern.ch/lcg/views/setupViews.sh LCG_97apython3 ${LCG_ARCHITECTURE}
    - export PATH=/cvmfs/lhcb.cern.ch/lib/var/lib/LbEnv/1043/stable/linux-64/bin:$PATH
    - if [ "${TARGET}" = "CPU" ]; then
    - cmake -DSTANDALONE=ON -GNinja -DTARGET_DEVICE=${TARGET} -DCMAKE_BUILD_TYPE=${BUILD_TYPE} -DSEQUENCE=${SEQUENCE} -DCPU_ARCH=haswell ${ADDITIONAL_OPTIONS} ..
    - elif [ "${TARGET}" = "HIP" ]; then
    - source /cvmfs/lhcbdev.cern.ch/tools/rocm-3.9.0/setenv.sh
    - cmake -DSTANDALONE=ON -GNinja -DTARGET_DEVICE=${TARGET} -DCMAKE_BUILD_TYPE=${BUILD_TYPE} -DSEQUENCE=${SEQUENCE} -DCPU_ARCH=haswell ${ADDITIONAL_OPTIONS} ..
    - else
    - source /cvmfs/sft.cern.ch/lcg/contrib/cuda/11.1/x86_64-centos7/setup.sh
    - OVERRIDE_CUDA_ARCH_FLAG="-gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_86,code=sm_86"
    - cmake -DSTANDALONE=ON -GNinja -DTARGET_DEVICE=${TARGET} -DCMAKE_BUILD_TYPE=${BUILD_TYPE} -DSEQUENCE=${SEQUENCE} -DCPU_ARCH=haswell -DOVERRIDE_CUDA_ARCH_FLAG="${OVERRIDE_CUDA_ARCH_FLAG}" ${ADDITIONAL_OPTIONS} ..
    - fi
    - ninja
  artifacts:
    expire_in: 1 day
    paths:
      - build*/*Allen*
      - build*/Sequence.json
      - input
  retry: 2
  needs: []

.build_job_with_tests: &build_job_with_tests_def
  variables:
    GIT_SUBMODULE_STRATEGY: recursive
  only:
    refs:
      - master
      - schedules
      - web
  stage: build
  script:
    - PREVIOUS_IFS=${IFS}
    - IFS=':' read -ra JOB_NAME_SPLIT <<< "${CI_JOB_NAME}"
    - IFS=${PREVIOUS_IFS}
    - TARGET=${JOB_NAME_SPLIT[0]}
    - SEQUENCE=${JOB_NAME_SPLIT[1]}
    - BUILD_TYPE=${JOB_NAME_SPLIT[2]}
    - ADDITIONAL_OPTIONS="${JOB_NAME_SPLIT[3]}"
    - LCG_ARCHITECTURE=${JOB_NAME_SPLIT[4]}
    - mkdir build_${TARGET}
    - cd build_${TARGET}
    - yum install -y numactl-libs
    - source /cvmfs/sft.cern.ch/lcg/views/setupViews.sh LCG_97apython3 ${LCG_ARCHITECTURE}
    - export PATH=/cvmfs/lhcb.cern.ch/lib/var/lib/LbEnv/1043/stable/linux-64/bin:$PATH
    - if [ "${TARGET}" = "CPU" ]; then
    - cmake -DSTANDALONE=ON -GNinja -DENABLE_CONTRACTS=ON -DTARGET_DEVICE=${TARGET} -DCMAKE_BUILD_TYPE=${BUILD_TYPE} -DBUILD_TESTS=ON -DSEQUENCE=${SEQUENCE} -DCPU_ARCH=haswell ${ADDITIONAL_OPTIONS} ..
    - elif [ "${TARGET}" = "HIP" ]; then
    - source /cvmfs/lhcbdev.cern.ch/tools/rocm-3.9.0/setenv.sh
    - cmake -DSTANDALONE=ON -GNinja -DENABLE_CONTRACTS=ON -DTARGET_DEVICE=${TARGET} -DCMAKE_BUILD_TYPE=${BUILD_TYPE} -DBUILD_TESTS=ON-DSEQUENCE=${SEQUENCE} -DCPU_ARCH=haswell ${ADDITIONAL_OPTIONS} ..
    - else
    - source /cvmfs/sft.cern.ch/lcg/contrib/cuda/11.1/x86_64-centos7/setup.sh
    - OVERRIDE_CUDA_ARCH_FLAG="-gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_86,code=sm_86"
    - cmake -DSTANDALONE=ON -GNinja -DENABLE_CONTRACTS=ON -DTARGET_DEVICE=${TARGET} -DCMAKE_BUILD_TYPE=${BUILD_TYPE} -DBUILD_TESTS=ON -DSEQUENCE=${SEQUENCE} -DCPU_ARCH=haswell -DOVERRIDE_CUDA_ARCH_FLAG="${OVERRIDE_CUDA_ARCH_FLAG}" ${ADDITIONAL_OPTIONS} ..
    - fi
    - ninja
  artifacts:
    expire_in: 1 day
    paths:
      - build*/*Allen*
      - build*/Sequence.json
      - input
      - build*/CTestTestfile.cmake
      - build*/test/unit_tests/unit_tests
      - build*/test/unit_tests/*cmake
  retry: 2
  needs: []
  tags:
    - cvmfs

docker_image:build:
  stage: build
  only:
    refs:
      - master
      - web
      - schedules
  tags:
    - docker-image-build
  script: "echo 'Building Allen dev docker image"
  variables:
    TO: $CI_REGISTRY_IMAGE:latest
    GIT_SUBMODULE_STRATEGY: recursive
  allow_failure: true
  needs: []

.run_physics_efficiency_job: &run_physics_efficiency_job_def
  only:
    refs:
      - master
      - web
      - schedules
  stage: run
  script:
    - |
      # Read job parameters.
      TOPLEVEL=${PWD}
      PREVIOUS_IFS=${IFS}
      IFS=':' read -ra JOB_NAME_SPLIT <<< "${CI_JOB_NAME}"
      IFS=':' read -ra CI_RUNNER_DESCRIPTION_SPLIT <<< "${CI_RUNNER_DESCRIPTION}"
      IFS=${PREVIOUS_IFS}

      DEVICE_ID=${JOB_NAME_SPLIT[0]}
      TARGET=${JOB_NAME_SPLIT[1]}
      SEQUENCE=${JOB_NAME_SPLIT[2]}
      LCG_ARCHITECTURE=${JOB_NAME_SPLIT[3]}
      DATA_TAG=${JOB_NAME_SPLIT[4]}
      RUN_OPTIONS="-n 1000 -m 1000"

      # Configure the input files (-f) and geometry (-g)

      if [ ! -z ${GEOMETRY+x} ]; then
        RUN_OPTIONS="${RUN_OPTIONS} -g ${ALLEN_DATA}/${GEOMETRY}"
      fi

      # INPUT_FILES will override DATA_TAG
      if [ ! -z ${INPUT_FILES+x} ]; then
        RUN_OPTIONS="${RUN_OPTIONS} -f ${ALLEN_DATA}/${INPUT_FILES}"
      else
        RUN_OPTIONS="${RUN_OPTIONS} -f ${ALLEN_DATA}/${DATA_TAG}"
      fi

    - |
      source /cvmfs/sft.cern.ch/lcg/views/setupViews.sh ${LCG_VERSION} ${LCG_ARCHITECTURE}
      mkdir validation_output && ln -s validation_output output # Needed by Root build

      cd build_${TARGET} && ls
      export LD_LIBRARY_PATH=${PWD}:$LD_LIBRARY_PATH

    - |
      JOB="./Allen ${RUN_OPTIONS}"
      if [ "${TARGET}" = "CPU" ]; then
        NUMA_NODE=${CI_RUNNER_DESCRIPTION_SPLIT[2]}
        ALLEN="numactl --cpunodebind=${NUMA_NODE} --membind=${NUMA_NODE} ${JOB}"
      else
        GPU_UUID=${CI_RUNNER_DESCRIPTION_SPLIT[2]}
        GPU_NUMBER=`nvidia-smi -L | grep ${GPU_UUID} | awk '{ print $2; }' | sed -e 's/://'`
        NUMA_NODE=`nvidia-smi topo -m | grep GPU${GPU_NUMBER} | tail -1 | awk '{ print $NF; }'`
        export PATH=$PATH:/usr/local/cuda/bin
        ALLEN="CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=${GPU_NUMBER} numactl --cpunodebind=${NUMA_NODE} --membind=${NUMA_NODE} ${JOB}"
      fi
      echo "Command: ${ALLEN}"

    - ( eval "${ALLEN}" )  2>&1 | tee ../validation_output/${DATA_TAG}_${DEVICE_ID}.txt

  artifacts:
    expire_in: 1 day
    paths:
      - validation_output/*
  allow_failure: true

.test_phys_eff_job: &test_phys_eff_job
  only:
    refs:
      - master
      - web
      - schedules
  stage: test
  script:
    - TOPLEVEL=${PWD}
    - ls validation_output
    - ls ${TOPLEVEL}/test/reference
    - cd validation_output
    - for i in $( ls ); do echo "Checking ${i}"; tail -n97 ${i} | head -n94 > efficiency_${i}; diff --ignore-trailing-space -u ${TOPLEVEL}/test/reference/${i} efficiency_${i} | tee ${i}_diff || true; done
    - cat *_diff > alldiffs
    - if [ -s alldiffs ]; then echo "Differences were found against reference files."; exit 1; else echo "No differences found against reference files."; exit 0; fi
  tags:
    - cvmfs
  artifacts:
    expire_in: 1 week
    when: on_failure
    paths:
      - validation_output/*_diff
  allow_failure: true

.run_with_run_changes_job: &run_with_run_changes_job_def
  only:
    refs:
      - master
      - web
      - schedules
  stage: run

  variables:
    MDF_INPUT: "mdf/upgrade_mc_minbias_scifi_v5_000.mdf"
    INPUT_FILES: "minbias_mag_down_201907"

  script:
    - |
      # Read job parameters.
      TOPLEVEL=${PWD}
      PREVIOUS_IFS=${IFS}
      IFS=':' read -ra JOB_NAME_SPLIT <<< "${CI_JOB_NAME}"
      IFS=':' read -ra CI_RUNNER_DESCRIPTION_SPLIT <<< "${CI_RUNNER_DESCRIPTION}"
      IFS=${PREVIOUS_IFS}

      DEVICE_ID=${JOB_NAME_SPLIT[0]}
      TARGET=${JOB_NAME_SPLIT[1]}
      SEQUENCE=${JOB_NAME_SPLIT[2]}
      LCG_ARCHITECTURE=${JOB_NAME_SPLIT[3]}
      RUN_OPTIONS="-n 1000 -m 700 --disable-run-changes 0"

      JOB="./Allen --mdf ${ALLEN_DATA}/${MDF_INPUT}-f ${ALLEN_DATA}/${INPUT_FILES} ${RUN_OPTIONS}"

      source /cvmfs/sft.cern.ch/lcg/views/setupViews.sh ${LCG_VERSION} ${LCG_ARCHITECTURE}
      mkdir run_changes_output && ln -s run_changes_output output # Needed by Root build
      cd build_${TARGET} && ls
      export LD_LIBRARY_PATH=${PWD}:$LD_LIBRARY_PATH

    - |
      # Configure job for target device.
      if [ "${TARGET}" = "CPU" ]; then
        NUMA_NODE=${CI_RUNNER_DESCRIPTION_SPLIT[2]}
        ALLEN="numactl --cpunodebind=${NUMA_NODE} --membind=${NUMA_NODE} ${JOB}"
      else
        GPU_UUID=${CI_RUNNER_DESCRIPTION_SPLIT[2]}
        GPU_NUMBER=`nvidia-smi -L | grep ${GPU_UUID} | awk '{ print $2; }' | sed -e 's/://'`
        NUMA_NODE=`nvidia-smi topo -m | grep GPU${GPU_NUMBER} | tail -1 | awk '{ print $NF; }'`
        export PATH=$PATH:/usr/local/cuda/bin
        ALLEN="CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=${GPU_NUMBER} numactl --cpunodebind=${NUMA_NODE} --membind=${NUMA_NODE} ${JOB}"
      fi
      echo "Command: ${ALLEN}"

    - ( eval "${ALLEN}" ) 2>&1 | tee ../run_changes_output/minbias_${DEVICE_ID}.txt

  artifacts:
    expire_in: 1 day
    paths:
      - run_changes_output/*
  allow_failure: true

.run_no_run_changes_job: &run_no_run_changes_job_def
  only:
    refs:
      - master
      - web
      - schedules
  stage: run
  script:
    - |
      # Read job parameters.
      TOPLEVEL=${PWD}
      PREVIOUS_IFS=${IFS}
      IFS=':' read -ra JOB_NAME_SPLIT <<< "${CI_JOB_NAME}"
      IFS=':' read -ra CI_RUNNER_DESCRIPTION_SPLIT <<< "${CI_RUNNER_DESCRIPTION}"
      IFS=${PREVIOUS_IFS}

      DEVICE_ID=${JOB_NAME_SPLIT[0]}
      TARGET=${JOB_NAME_SPLIT[1]}
      SEQUENCE=${JOB_NAME_SPLIT[2]}
      LCG_ARCHITECTURE=${JOB_NAME_SPLIT[3]}

      JOB="./Allen --mdf ${ALLEN_DATA}/mdf/upgrade_mc_minbias_scifi_v5_000.mdf -f ${ALLEN_DATA}/minbias_mag_down_201907 -n 1000 -m 700 --disable-run-changes 1"

      source /cvmfs/sft.cern.ch/lcg/views/setupViews.sh ${LCG_VERSION} ${LCG_ARCHITECTURE}
      mkdir no_run_changes_output && ln -s no_run_changes_output output # Needed by Root build
      cd build_${TARGET} && ls
      export LD_LIBRARY_PATH=${PWD}:$LD_LIBRARY_PATH

    - |
      # Configure job for target device.
      if [ "${TARGET}" = "CPU" ]; then
        NUMA_NODE=${CI_RUNNER_DESCRIPTION_SPLIT[2]}
        ALLEN="numactl --cpunodebind=${NUMA_NODE} --membind=${NUMA_NODE} ${JOB}"
      else
        GPU_UUID=${CI_RUNNER_DESCRIPTION_SPLIT[2]}
        GPU_NUMBER=`nvidia-smi -L | grep ${GPU_UUID} | awk '{ print $2; }' | sed -e 's/://'`
        NUMA_NODE=`nvidia-smi topo -m | grep GPU${GPU_NUMBER} | tail -1 | awk '{ print $NF; }'`
        export PATH=$PATH:/usr/local/cuda/bin
        ALLEN="CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=${GPU_NUMBER} numactl --cpunodebind=${NUMA_NODE} --membind=${NUMA_NODE} ${JOB}"
      fi

    - ( eval "${ALLEN}" ) 2>&1 | tee ../no_run_changes_output/minbias_${DEVICE_ID}.txt

  artifacts:
    expire_in: 1 day
    paths:
      - no_run_changes_output/*
  allow_failure: true

.run_throughput_job_no_profiling: &run_throughput_job_no_profiling_def
  only:
    refs:
      - master
      - web
      - schedules
  stage: run
  script:
    - |
      # Read job parameters.
      TOPLEVEL=${PWD}
      PREVIOUS_IFS=${IFS}
      IFS=':' read -ra JOB_NAME_SPLIT <<< "${CI_JOB_NAME}"
      IFS=':' read -ra CI_RUNNER_DESCRIPTION_SPLIT <<< "${CI_RUNNER_DESCRIPTION}"
      IFS=${PREVIOUS_IFS}
      DEVICE_ID=${JOB_NAME_SPLIT[0]}
      TARGET=${JOB_NAME_SPLIT[1]}
      SEQUENCE=${JOB_NAME_SPLIT[2]}
      LCG_ARCHITECTURE=${JOB_NAME_SPLIT[3]}
      DATA_TAG=${JOB_NAME_SPLIT[4]}

    - |
      source /cvmfs/sft.cern.ch/lcg/views/setupViews.sh ${LCG_VERSION} ${LCG_ARCHITECTURE}

    - |
      mkdir output_${DEVICE_ID} && cd build_${TARGET} && ls
      export LD_LIBRARY_PATH=${PWD}:$LD_LIBRARY_PATH

    - |
      # Configure RUN_OPTIONS.
      # If already defined, let it stick.
      if [ ! -z ${RUN_OPTIONS+x} ]; then
        RUN_OPTIONS=""
      fi

      # if a geometry folder is specified, pass it to Allen.
      if [ ! -z ${GEOMETRY+x} ]; then
        RUN_OPTIONS="$RUN_OPTIONS -g ${ALLEN_DATA}/${GEOMETRY}"
      fi

      # if INPUT_FILES is set, use that instead of $DATA_TAG
      # otherwise, keep normal behaviour.
      if [ ! -z ${INPUT_FILES+x} ]; then
        RUN_OPTIONS="-f ${ALLEN_DATA}/${INPUT_FILES} ${RUN_OPTIONS}"
      else
        RUN_OPTIONS="-f ${ALLEN_DATA}/${DATA_TAG} ${RUN_OPTIONS}"
      fi

    - |
      # Configure job for target device.
      if [ "${TARGET}" = "CPU" ]; then
        TOTAL_THREADS=$(lscpu | egrep "^CPU\(s\):.*[0-9]+$" --color=none | awk '{ print $2; }')
        TOTAL_NUMA_NODES=$(lscpu | egrep "^NUMA node\(s\):.*[0-9]+$" --color=none | awk '{ print $3; }')
        NUMA_NODE=${CI_RUNNER_DESCRIPTION_SPLIT[2]}
        THREADS=$((${TOTAL_THREADS} / ${TOTAL_NUMA_NODES}))
        RUN_OPTIONS="${RUN_OPTIONS} -n 100 -m 100 -r 200 -t ${THREADS} -c 0"

        ALLEN="numactl --cpunodebind=${NUMA_NODE} --membind=${NUMA_NODE} ./Allen ${RUN_OPTIONS}"
      else
        export PATH=$PATH:/usr/local/cuda/bin
        GPU_UUID=${CI_RUNNER_DESCRIPTION_SPLIT[2]}
        GPU_NUMBER=`nvidia-smi -L | grep ${GPU_UUID} | awk '{ print $2; }' | sed -e 's/://'`
        NUMA_NODE=`nvidia-smi topo -m | grep GPU${GPU_NUMBER} | tail -1 | awk '{ print $NF; }'`
        RUN_OPTIONS="${RUN_OPTIONS} -n 500 -m 500 -r 1000 -t 16 -c 0"

        ALLEN="CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=${GPU_NUMBER} numactl --cpunodebind=${NUMA_NODE} --membind=${NUMA_NODE} ./Allen ${RUN_OPTIONS}"
      fi
      echo "Command: ${ALLEN}"

    - ( eval "${ALLEN}" ) 2>&1 | tee ../output_${DEVICE_ID}/output.txt

  artifacts:
    expire_in: 1 day
    paths:
      - output_*
  allow_failure: true

.run_throughput_job: &run_throughput_job_def
  only:
    refs:
      - master
      - web
      - schedules
  stage: run
  script:
    - |
      TOPLEVEL=${PWD}
      PREVIOUS_IFS=${IFS}
      IFS=':' read -ra JOB_NAME_SPLIT <<< "${CI_JOB_NAME}"
      IFS=':' read -ra CI_RUNNER_DESCRIPTION_SPLIT <<< "${CI_RUNNER_DESCRIPTION}"
      IFS=${PREVIOUS_IFS}

      DEVICE_ID=${JOB_NAME_SPLIT[0]}
      TARGET=${JOB_NAME_SPLIT[1]}
      SEQUENCE=${JOB_NAME_SPLIT[2]}
      LCG_ARCHITECTURE=${JOB_NAME_SPLIT[3]}
      DATA_TAG=${JOB_NAME_SPLIT[4]}
      RUN_OPTIONS=""

      # if a geometry folder is specified, pass it to Allen.
      if [ ! -z ${GEOMETRY+x} ]; then
        RUN_OPTIONS="$RUN_OPTIONS -g ${ALLEN_DATA}/${GEOMETRY}"
      fi

      # if INPUT_FILES is set, use that instead of $DATA_TAG
      # otherwise, keep normal behaviour.
      if [ ! -z ${INPUT_FILES+x} ]; then
        RUN_OPTIONS="-f ${ALLEN_DATA}/${INPUT_FILES} ${RUN_OPTIONS}"
      else
        INPUT_FILES="${DATA_TAG}"
        RUN_OPTIONS="-f ${ALLEN_DATA}/${DATA_TAG} ${RUN_OPTIONS}"
      fi

      GPU_UUID=${CI_RUNNER_DESCRIPTION_SPLIT[2]}
      GPU_NUMBER=`nvidia-smi -L | grep ${GPU_UUID} | awk '{ print $2; }' | sed -e 's/://'`
      NUMA_NODE=`nvidia-smi topo -m | grep GPU${GPU_NUMBER} | tail -1 | awk '{ print $NF; }'`
      RUN_PROFILER_OPTIONS="-n 500 -m 500 -r 100 -t 1 -c 0 ${RUN_OPTIONS}"
      RUN_OPTIONS="-n 500 -m 500 -r 1000 -t 16 -c 0 ${RUN_OPTIONS}"
      export PATH=$PATH:/usr/local/cuda/bin

    - source /cvmfs/sft.cern.ch/lcg/views/setupViews.sh ${LCG_VERSION} ${LCG_ARCHITECTURE}

    - |
      mkdir output_${DEVICE_ID} && cd build_${TARGET} && ls
      export LD_LIBRARY_PATH=${PWD}:$LD_LIBRARY_PATH
      mkdir tmp

    - CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=${GPU_NUMBER} numactl --cpunodebind=${NUMA_NODE} --membind=${NUMA_NODE} ./Allen ${RUN_OPTIONS} 2>&1 | tee ../output_${DEVICE_ID}/output.txt
    - CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=${GPU_NUMBER} TMPDIR=tmp numactl --cpunodebind=${NUMA_NODE} --membind=${NUMA_NODE} nsys profile --trace=cuda ./Allen ${RUN_PROFILER_OPTIONS}
    - nsys stats --report gpukernsum report1.qdrep -o allen_report
    - python3 ${TOPLEVEL}/checker/plotting/extract_algo_breakdown.py -f allen_report_gpukernsum.csv -d ../output_${DEVICE_ID}

    - rm -rf report1.qdrep tmp
  artifacts:
    expire_in: 1 day
    paths:
      - output_*
  allow_failure: true

.throughput_cli_plot_job: &publish_algo_breakdown_plot_def
  only:
    refs:
      - master
      - web
      - schedules
  stage: publish
  script:
    - PREVIOUS_IFS=${IFS}
    - IFS=':' read -ra JOB_NAME_SPLIT <<< "${CI_JOB_NAME}"
    - IFS=${PREVIOUS_IFS}
    - DEVICE_ID=${JOB_NAME_SPLIT[0]}
    - SEQUENCE=${JOB_NAME_SPLIT[1]}
    - export PATH=$PATH:/usr/local/cuda/bin
    - source /cvmfs/sft.cern.ch/lcg/views/setupViews.sh ${LCG_VERSION} x86_64-centos7-clang10-opt
    - python3 checker/plotting/csv_plotter.py -t "Algorithm Breakdown of sequence ${SEQUENCE}, branch ${CI_COMMIT_REF_NAME}" -u "%" -x 30 -m ${MATTERMOST_KEY} output_${DEVICE_ID}/algo_breakdown.csv

test_physics_efficiency:
  <<: *test_phys_eff_job
  needs:
    - geforcertx2080ti:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:bsphiphi_mag_down_201907:run_physics_efficiency
    - x862630v4:CPU:hlt1_pp_default:x86_64-centos7-clang10-opt:bsphiphi_mag_down_201907:run_physics_efficiency
  <<: *active_branches

test_run_changes:
  only:
    refs:
      - master
      - web
      - schedules
  stage: test
  script:
    - TOPLEVEL=${PWD}
    - ls run_changes_output
    - ls no_run_changes_output
    - cd run_changes_output
    - for i in $( ls ); do echo "Checking ${i}"; tail -n98 ${i} | head -n94 > run_changes_${i}; tail -n98 ${TOPLEVEL}/no_run_changes_output/${i} | head -n94 > no_run_changes_${i}; diff -u no_run_changes_${i} run_changes_${i} | tee ${i}_diff || true; done
    - cat *_diff > alldiffs
    - if [ -s alldiffs ]; then echo "Differences were found against output without run change splitting."; exit 1; else echo "No differences found against output without run change splitting."; exit 0; fi
  needs:
    - geforcertx2080ti:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:run_with_run_changes
    - geforcertx2080ti:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:run_no_run_changes
    - x862630v4:CPU:hlt1_pp_default:x86_64-centos7-clang10-opt:run_with_run_changes
    - x862630v4:CPU:hlt1_pp_default:x86_64-centos7-clang10-opt:run_no_run_changes
  tags:
    - cvmfs
  allow_failure: true

.run_built_tests: &run_built_tests_job
  only:
    refs:
      - master
      - schedules
      - web
  stage: test
  script:
    - PREVIOUS_IFS=${IFS}
    - IFS=':' read -ra JOB_NAME_SPLIT <<< "${CI_JOB_NAME}"
    - IFS=':' read -ra CI_RUNNER_DESCRIPTION_SPLIT <<< "${CI_RUNNER_DESCRIPTION}"
    - IFS=${PREVIOUS_IFS}
    - TARGET=${JOB_NAME_SPLIT[0]}
    - LCG_ARCHITECTURE=${JOB_NAME_SPLIT[3]}
    - source /cvmfs/sft.cern.ch/lcg/views/setupViews.sh LCG_97apython3 ${LCG_ARCHITECTURE}
    - cd build_${TARGET}
    - BUILD_DIR=`cat CTestTestfile.cmake | grep "# Build directory:" | awk '{ print $4 }'`
    - REPLACEMENT_DIR=${PWD}
    - sed -i CTestTestfile.cmake -e s:${BUILD_DIR}:${REPLACEMENT_DIR}:g
    - sed -i test/unit_tests/*.cmake -e s:${BUILD_DIR}:${REPLACEMENT_DIR}:g
    - if [ "${TARGET}" = "CPU" ]; then
    - TOTAL_THREADS=$(lscpu | egrep "^CPU\(s\):.*[0-9]+$" --color=none | awk '{ print $2; }')
    - TOTAL_NUMA_NODES=$(lscpu | egrep "^NUMA node\(s\):.*[0-9]+$" --color=none | awk '{ print $3; }')
    - NUMA_NODE=${CI_RUNNER_DESCRIPTION_SPLIT[2]}
    - THREADS=$((${TOTAL_THREADS} / ${TOTAL_NUMA_NODES}))
    - LD_LIBRARY_PATH=$PWD:$LD_LIBRARY_PATH numactl --cpunodebind=${NUMA_NODE} --membind=${NUMA_NODE} ctest -V -j ${THREADS}
    - else
    - GPU_UUID=${CI_RUNNER_DESCRIPTION_SPLIT[2]}
    - GPU_NUMBER=`nvidia-smi -L | grep ${GPU_UUID} | awk '{ print $2; }' | sed -e 's/://'`
    - NUMA_NODE=`nvidia-smi topo -m | grep GPU${GPU_NUMBER} | tail -1 | awk '{ print $8; }'`
    - export PATH=$PATH:/usr/local/cuda/bin
    - LD_LIBRARY_PATH=$PWD:$LD_LIBRARY_PATH CUDA_DEVICE_ORDER=PCI_BUS_ID CUDA_VISIBLE_DEVICES=${GPU_NUMBER} numactl --cpunodebind=${NUMA_NODE} --membind=${NUMA_NODE} ctest -V
    - fi
  allow_failure: true

.publish_throughput_job: &publish_throughput_job_def
  only:
    refs:
      - master
      - web
      - schedules
  stage: publish
  script:
    - PREVIOUS_IFS=${IFS}
    - IFS=':' read -ra JOB_NAME_SPLIT <<< "${CI_JOB_NAME}"
    - IFS=${PREVIOUS_IFS}
    - SEQUENCE=${JOB_NAME_SPLIT[1]}
    - BREAKDOWN_DEVICE_ID=${JOB_NAME_SPLIT[2]}
    - DATA_TAG=${JOB_NAME_SPLIT[3]}
    - cat output_*/output.txt | grep --color=none "select device" | sed 's/.*:\ [0-9]*\,\ //' > devices.txt
    - cat output_*/output.txt | grep --color=none "events/s" | awk '{ print $1; }' > throughputs.txt
    - cat devices.txt
    - cat throughputs.txt
    - paste -d, devices.txt throughputs.txt > devices_throughputs.csv
    - cat devices_throughputs.csv
    - source /cvmfs/sft.cern.ch/lcg/views/setupViews.sh ${LCG_VERSION} x86_64-centos7-clang10-opt
    - python3 checker/plotting/post_combined_message.py -j "${CI_JOB_NAME}" -l "Throughput of [branch ${CI_COMMIT_REF_NAME}, sequence ${SEQUENCE} over dataset ${DATA_TAG}](https://gitlab.cern.ch/lhcb/Allen/pipelines/${CI_PIPELINE_ID})" -m ${MATTERMOST_KEY} -t devices_throughputs.csv -b output_${BREAKDOWN_DEVICE_ID}/algo_breakdown.csv
    - python3 checker/plotting/post_telegraf.py -d . -s ${SEQUENCE} -b ${CI_COMMIT_REF_NAME}

# =====
# Build
# =====

CUDA:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build:
  <<: *build_job_def
  <<: *active_branches

CPU:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build:
  <<: *build_job_def
  <<: *active_branches

HIP:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build:
  <<: *build_job_def
  <<: *active_branches

CUDA:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build_with_tests:
  <<: *build_job_with_tests_def
  tags:
    - cvmfs

CPU:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build_with_tests:
  <<: *build_job_with_tests_def
  tags:
    - cvmfs
      
HIP:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build_with_tests:
  <<: *build_job_with_tests_def
  tags:
    - cvmfs

CUDA:hlt1_pp_default:Debug:-DUSE_ROOT=ON:x86_64-centos7-clang10-opt:build_with_tests:
  <<: *build_job_with_tests_def
  tags:
    - cvmfs

CPU:hlt1_pp_default:Debug:-DUSE_ROOT=ON:x86_64-centos7-clang10-opt:build_with_tests:
  <<: *build_job_with_tests_def
  tags:
    - cvmfs

HIP:hlt1_pp_default:Debug:-DUSE_ROOT=ON:x86_64-centos7-clang10-opt:build_with_tests:
  <<: *build_job_with_tests_def
  tags:
    - cvmfs

# Builds with warnings treated as errors
# gcc:

CPU:hlt1_pp_default:Debug:-DUSE_ROOT=ON -DTREAT_WARNINGS_AS_ERRORS=ON:x86_64-centos7-gcc9-opt:build_warnings_as_errors:
  <<: *build_job_with_tests_def
  tags:
    - cvmfs

CUDA:hlt1_pp_default:Debug:-DUSE_ROOT=ON -DTREAT_WARNINGS_AS_ERRORS=ON:x86_64-centos7-gcc9-opt:build_warnings_as_errors:
  <<: *build_job_with_tests_def
  tags:
    - cvmfs

HIP:hlt1_pp_default:Debug:-DUSE_ROOT=ON -DTREAT_WARNINGS_AS_ERRORS=ON:x86_64-centos7-gcc9-opt:build_warnings_as_errors:
  <<: *build_job_with_tests_def
  tags:
    - cvmfs

# clang:

CPU:hlt1_pp_default:Debug:-DUSE_ROOT=ON -DTREAT_WARNINGS_AS_ERRORS=ON:x86_64-centos7-clang10-opt:build_warnings_as_errors:
  <<: *build_job_with_tests_def
  tags:
    - cvmfs
  only:
    refs:
      - master
      - web
      - schedules
      - merge_requests
    
CUDA:hlt1_pp_default:Debug:-DUSE_ROOT=ON -DTREAT_WARNINGS_AS_ERRORS=ON:x86_64-centos7-clang10-opt:build_warnings_as_errors:
  <<: *build_job_with_tests_def
  tags:
    - cvmfs
  only:
    refs:
      - master
      - web
      - schedules
      - merge_requests

HIP:hlt1_pp_default:Debug:-DUSE_ROOT=ON -DTREAT_WARNINGS_AS_ERRORS=ON:x86_64-centos7-clang10-opt:build_warnings_as_errors:
  <<: *build_job_with_tests_def
  tags:
    - cvmfs
  <<: *active_branches

# Build of default sequence without code generation

CPU:hlt1_pp_default:Debug:-DUSE_ROOT=ON -DSEQUENCE_GENERATION=OFF:x86_64-centos7-clang10-opt:build_with_tests:
  <<: *build_job_with_tests_def
  tags:
    - cvmfs

# Builds only on master of additional options

CUDA:hlt1_pp_no_gec:RelWithDebInfo::x86_64-centos7-clang10-opt:build:
  <<: *build_job_def

CPU:hlt1_pp_no_gec:RelWithDebInfo::x86_64-centos7-clang10-opt:build:
  <<: *build_job_def


# Build SciFi v6 sequence

# clang opt, RelWithDebInfo, [ CUDA, CPU, HIP ]

CUDA:hlt1_pp_scifi_v6:RelWithDebInfo::x86_64-centos7-clang10-opt:build:
  <<: *build_job_def

  <<: *active_branches

CPU:hlt1_pp_scifi_v6:RelWithDebInfo::x86_64-centos7-clang10-opt:build:
  <<: *build_job_def
  <<: *active_branches

HIP:hlt1_pp_scifi_v6:RelWithDebInfo::x86_64-centos7-clang10-opt:build:
  <<: *build_job_def
  <<: *active_branches

# ===
# Run
# ===

# Throughput runs

geforcertx2080ti:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - geforcertx2080ti
  needs:
    - CUDA:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build
  <<: *active_branches


quadrortx6000:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - quadrortx6000
  needs:
    - CUDA:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build
  <<: *active_branches


teslav100:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - teslav100
  needs:
    - CUDA:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build
  <<: *active_branches


geforcertx3080:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - geforcertx3080
  needs:
    - CUDA:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build
  <<: *active_branches


geforcertx3090:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput:
  <<: *run_throughput_job_def
  tags:
    - geforcertx3090
  needs:
    - CUDA:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build
  <<: *active_branches


x862630v4:CPU:hlt1_pp_default:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - x862630v4
  needs:
    - CPU:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build
  <<: *active_branches


epyc7502:CPU:hlt1_pp_default:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - epyc7502
  needs:
    - CPU:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build
  <<: *active_branches



### SciFi v6 throughput jobs
.scifi_v6_throughput_job_data: &scifi_v6_throughput_job_data
  variables:
    INPUT_FILES: "SciFiv6_upgrade_DC19_01_MinBiasMD"
    GEOMETRY: "SciFiv6_upgrade_DC19_01_geom"
  <<: *active_branches

.scifi_v6_throughput_job: &scifi_v6_throughput_job
  <<: *run_throughput_job_no_profiling_def
  <<: *scifi_v6_throughput_job_data

.scifi_v6_throughput_job_profiling: &scifi_v6_throughput_job_profiling
  <<: *run_throughput_job_def
  <<: *scifi_v6_throughput_job_data


.scifi_v6_efficiency_data: &scifi_v6_efficiency_data
  variables:
    INPUT_FILES: "SciFiv6_upgrade_DC19_01_Bs2PhiPhiMD"
    GEOMETRY: "SciFiv6_upgrade_DC19_01_geom"
  <<: *active_branches

geforcertx2080ti:CUDA:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_MinBiasMD:run_throughput:
  <<: *scifi_v6_throughput_job
  tags:
    - geforcertx2080ti
  needs:
    - CUDA:hlt1_pp_scifi_v6:RelWithDebInfo::x86_64-centos7-clang10-opt:build


quadrortx6000:CUDA:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_MinBiasMD:run_throughput:
  <<: *scifi_v6_throughput_job
  tags:
    - quadrortx6000
  needs:
    - CUDA:hlt1_pp_scifi_v6:RelWithDebInfo::x86_64-centos7-clang10-opt:build

teslav100:CUDA:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_MinBiasMD:run_throughput:
  <<: *scifi_v6_throughput_job
  tags:
    - teslav100
  needs:
    - CUDA:hlt1_pp_scifi_v6:RelWithDebInfo::x86_64-centos7-clang10-opt:build

geforcertx3080:CUDA:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_MinBiasMD:run_throughput:
  <<: *scifi_v6_throughput_job
  tags:
    - geforcertx3080
  needs:
    - CUDA:hlt1_pp_scifi_v6:RelWithDebInfo::x86_64-centos7-clang10-opt:build

geforcertx3090:CUDA:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_MinBiasMD:run_throughput:
  <<: *scifi_v6_throughput_job_profiling
  tags:
    - geforcertx3090
  needs:
    - CUDA:hlt1_pp_scifi_v6:RelWithDebInfo::x86_64-centos7-clang10-opt:build

x862630v4:CPU:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_MinBiasMD:run_throughput:
  <<: *scifi_v6_throughput_job
  tags:
    - x862630v4
  needs:
    - CPU:hlt1_pp_scifi_v6:RelWithDebInfo::x86_64-centos7-clang10-opt:build

epyc7502:CPU:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_MinBiasMD:run_throughput:
  <<: *scifi_v6_throughput_job
  tags:
    - epyc7502
  needs:
    - CPU:hlt1_pp_scifi_v6:RelWithDebInfo::x86_64-centos7-clang10-opt:build


# Physics efficiency runs

geforcertx2080ti:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:bsphiphi_mag_down_201907:run_physics_efficiency:
  <<: *run_physics_efficiency_job_def
  tags:
    - geforcertx2080ti
  needs:
    - CUDA:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build
  <<: *active_branches


x862630v4:CPU:hlt1_pp_default:x86_64-centos7-clang10-opt:bsphiphi_mag_down_201907:run_physics_efficiency:
  <<: *run_physics_efficiency_job_def
  tags:
    - x862630v4
  needs:
    - CPU:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build
  <<: *active_branches

# Efficiency for Sci

geforcertx2080ti:CUDA:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_Bs2PhiPhiMD:run_physics_efficiency:
  <<: *run_physics_efficiency_job_def
  <<: *scifi_v6_efficiency_data
  tags:
    - geforcertx2080ti
  needs:
    - CUDA:hlt1_pp_scifi_v6:RelWithDebInfo::x86_64-centos7-clang10-opt:build


x862630v4:CPU:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_Bs2PhiPhiMD:run_physics_efficiency:
  <<: *run_physics_efficiency_job_def
  <<: *scifi_v6_efficiency_data
  tags:
    - x862630v4
  needs:
    - CPU:hlt1_pp_scifi_v6:RelWithDebInfo::x86_64-centos7-clang10-opt:build




# Additional throughput runs, only on master

geforcertx2080ti:CUDA:hlt1_pp_no_gec:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - geforcertx2080ti
  needs:
    - CUDA:hlt1_pp_no_gec:RelWithDebInfo::x86_64-centos7-clang10-opt:build

quadrortx6000:CUDA:hlt1_pp_no_gec:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - quadrortx6000
  needs:
    - CUDA:hlt1_pp_no_gec:RelWithDebInfo::x86_64-centos7-clang10-opt:build

teslav100:CUDA:hlt1_pp_no_gec:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - teslav100
  needs:
    - CUDA:hlt1_pp_no_gec:RelWithDebInfo::x86_64-centos7-clang10-opt:build

geforcertx3080:CUDA:hlt1_pp_no_gec:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - geforcertx3080
  needs:
    - CUDA:hlt1_pp_no_gec:RelWithDebInfo::x86_64-centos7-clang10-opt:build

geforcertx3090:CUDA:hlt1_pp_no_gec:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput:
  <<: *run_throughput_job_def
  tags:
    - geforcertx3090
  needs:
    - CUDA:hlt1_pp_no_gec:RelWithDebInfo::x86_64-centos7-clang10-opt:build

x862630v4:CPU:hlt1_pp_no_gec:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - x862630v4
  needs:
    - CPU:hlt1_pp_no_gec:RelWithDebInfo::x86_64-centos7-clang10-opt:build

epyc7502:CPU:hlt1_pp_no_gec:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - epyc7502
  needs:
    - CPU:hlt1_pp_no_gec:RelWithDebInfo::x86_64-centos7-clang10-opt:build

geforcertx2080ti:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:SMOG2_pppHe:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - geforcertx2080ti
  needs:
    - CUDA:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build

quadrortx6000:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:SMOG2_pppHe:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - quadrortx6000
  needs:
    - CUDA:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build

teslav100:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:SMOG2_pppHe:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - teslav100
  needs:
    - CUDA:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build

geforcertx3080:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:SMOG2_pppHe:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - geforcertx3080
  needs:
    - CUDA:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build

geforcertx3090:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:SMOG2_pppHe:run_throughput:
  <<: *run_throughput_job_def
  tags:
    - geforcertx3090
  needs:
    - CUDA:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build

x862630v4:CPU:hlt1_pp_default:x86_64-centos7-clang10-opt:SMOG2_pppHe:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - x862630v4
  needs:
    - CPU:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build

epyc7502:CPU:hlt1_pp_default:x86_64-centos7-clang10-opt:SMOG2_pppHe:run_throughput:
  <<: *run_throughput_job_no_profiling_def
  tags:
    - epyc7502
  needs:
    - CPU:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build

# Run debug builds

geforcertx2080ti:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:bsphiphi_mag_down_201907:run_physics_efficiency_debug:
  <<: *run_physics_efficiency_job_def
  tags:
    - geforcertx2080ti
  needs:
    - CUDA:hlt1_pp_default:Debug:-DUSE_ROOT=ON:x86_64-centos7-clang10-opt:build_with_tests

x86:CPU:hlt1_pp_default:x86_64-centos7-clang10-opt:bsphiphi_mag_down_201907:run_physics_efficiency_debug:
  <<: *run_physics_efficiency_job_def
  tags:
    - x86
  needs:
    - CPU:hlt1_pp_default:Debug:-DUSE_ROOT=ON:x86_64-centos7-clang10-opt:build_with_tests

# check run changes

geforcertx2080ti:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:run_with_run_changes:
  <<: *run_with_run_changes_job_def
  tags:
    - geforcertx2080ti
  needs:
    - CUDA:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build

x862630v4:CPU:hlt1_pp_default:x86_64-centos7-clang10-opt:run_with_run_changes:
  <<: *run_with_run_changes_job_def
  tags:
    - x862630v4
  needs:
    - CPU:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build

geforcertx2080ti:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:run_no_run_changes:
  <<: *run_no_run_changes_job_def
  tags:
    - geforcertx2080ti
  needs:
    - CUDA:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build

x862630v4:CPU:hlt1_pp_default:x86_64-centos7-clang10-opt:run_no_run_changes:
  <<: *run_no_run_changes_job_def
  tags:
    - x862630v4
  needs:
    - CPU:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build

# ====
# Test
# ====

CPU:hlt1_pp_default:RelWithDebInfo:x86_64-centos7-clang10-opt:test:
  <<: *run_built_tests_job
  tags:
    - x862630v4
  needs:
    - CPU:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build_with_tests

CUDA:hlt1_pp_default:RelWithDebInfo:x86_64-centos7-clang10-opt:test:
  <<: *run_built_tests_job
  tags:
    - geforcertx2080ti
  needs:
    - CUDA:hlt1_pp_default:RelWithDebInfo::x86_64-centos7-clang10-opt:build_with_tests

CPU:hlt1_pp_default:Debug:x86_64-centos7-clang10-opt:test:
  <<: *run_built_tests_job
  tags:
    - x862630v4
  needs:
    - CPU:hlt1_pp_default:Debug:-DUSE_ROOT=ON:x86_64-centos7-clang10-opt:build_with_tests

CUDA:hlt1_pp_default:Debug:x86_64-centos7-clang10-opt:test:
  <<: *run_built_tests_job
  tags:
    - geforcertx2080ti
  needs:
    - CUDA:hlt1_pp_default:Debug:-DUSE_ROOT=ON:x86_64-centos7-clang10-opt:build_with_tests

# =======
# Publish
# =======

throughput:hlt1_pp_default:geforcertx3090:minbias_mag_down_201907:publish_throughput:
  <<: *publish_throughput_job_def
  tags:
    - cvmfs
  needs:
    - geforcertx2080ti:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput
    - quadrortx6000:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput
    - teslav100:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput
    - geforcertx3080:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput
    - geforcertx3090:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput
    - x862630v4:CPU:hlt1_pp_default:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput
    - epyc7502:CPU:hlt1_pp_default:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput
  <<: *active_branches

  artifacts:
    paths:
      - devices_throughputs.csv
    expire_in: 1 week

# Publish additional throughput tests, only in master

throughput:hlt1_pp_no_gec:geforcertx3090:minbias_mag_down_201907:publish_throughput:
  <<: *publish_throughput_job_def
  tags:
    - cvmfs
  needs:
    - geforcertx2080ti:CUDA:hlt1_pp_no_gec:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput
    - quadrortx6000:CUDA:hlt1_pp_no_gec:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput
    - teslav100:CUDA:hlt1_pp_no_gec:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput
    - geforcertx3080:CUDA:hlt1_pp_no_gec:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput
    - geforcertx3090:CUDA:hlt1_pp_no_gec:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput
    - x862630v4:CPU:hlt1_pp_no_gec:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput
    - epyc7502:CPU:hlt1_pp_no_gec:x86_64-centos7-clang10-opt:minbias_mag_down_201907:run_throughput
  artifacts:
    paths:
      - devices_throughputs.csv
    expire_in: 1 week

throughput:hlt1_pp_default:geforcertx3090:SMOG2_pppHe:publish_throughput:
  <<: *publish_throughput_job_def
  tags:
    - cvmfs
  needs:
    - geforcertx2080ti:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:SMOG2_pppHe:run_throughput
    - quadrortx6000:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:SMOG2_pppHe:run_throughput
    - teslav100:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:SMOG2_pppHe:run_throughput
    - geforcertx3080:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:SMOG2_pppHe:run_throughput
    - geforcertx3090:CUDA:hlt1_pp_default:x86_64-centos7-clang10-opt:SMOG2_pppHe:run_throughput
    - x862630v4:CPU:hlt1_pp_default:x86_64-centos7-clang10-opt:SMOG2_pppHe:run_throughput
    - epyc7502:CPU:hlt1_pp_default:x86_64-centos7-clang10-opt:SMOG2_pppHe:run_throughput
  artifacts:
    paths:
      - devices_throughputs.csv
    expire_in: 1 week

### SciFi v6 tests

.scifi-v6-jobs-for-publish-throughput: &scifi-v6-jobs-for-publish-throughput
  needs:
    - geforcertx2080ti:CUDA:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_MinBiasMD:run_throughput
    - quadrortx6000:CUDA:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_MinBiasMD:run_throughput
    - teslav100:CUDA:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_MinBiasMD:run_throughput
    - geforcertx3080:CUDA:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_MinBiasMD:run_throughput
    - geforcertx3090:CUDA:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_MinBiasMD:run_throughput
    - x862630v4:CPU:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_MinBiasMD:run_throughput
    - epyc7502:CPU:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_MinBiasMD:run_throughput
  tags:
    - x86
  artifacts:
    paths:
      - devices_throughputs.csv
    expire_in: 1 week

throughput:hlt1_pp_scifi_v6:geforcertx3090:SciFiv6_upgrade_DC19_01_MinBiasMD:publish_throughput:
  <<: *publish_throughput_job_def
  <<: *scifi-v6-jobs-for-publish-throughput
  <<: *active_branches

scifiv6_test_physics_efficiency:
  <<: *test_phys_eff_job
  <<: *active_branches
  needs:
    - geforcertx2080ti:CUDA:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_Bs2PhiPhiMD:run_physics_efficiency
    - x862630v4:CPU:hlt1_pp_scifi_v6:x86_64-centos7-clang10-opt:SciFiv6_upgrade_DC19_01_Bs2PhiPhiMD:run_physics_efficiency


